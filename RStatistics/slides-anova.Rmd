---
# https://garrettgman.github.io/rmarkdown/slidy_presentation_format.html
title: "Basic one and two-way ANOVA with R"
author: "Thomas Petzoldt"
date: "2021-01-04"
bibliography: bib.bib
output:
  slidy_presentation:
    font_adjustment: 0
    css: tp_slidy.css
    theme: default
    highlight: default
    #df_print: kable
    #mathjax: local
    pandoc_args: -V slidy-url=myslidy
    self_contained: no
---

Preface
--------------------------------------------------------------------------------

* Work in progress ...
* This HTML document is intended to amend the PDF lecture slides
* questions and comments to: https://tu-dresden.de/Members/thomas.petzoldt
* Photos and algae growth data were created as part of a highschool internship project
* Many thanks to C. Belger for his contribution.

<style>
 h2, h3 {
   color: #009de0;
   font-size: 40px;
}

div.vbox {
  float: left;
  height: 40%; width: 50%;
  margin-top: -220px;
}
div.hbox {
  width:60%;  margin-top: 0;
  margin-left:auto; margin-right:auto;
  height: 60%;
  border:1px solid silver;
  // background:#F0F0F0;
  overflow:auto;
  text-align:left;
  clear:both;
}
.math {
  font-size: 95%;
  padding-right: 1ex;
}
li::marker {
  color: orange;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("dplyr")
library("tidyr")
library("kableExtra")
mypar <- list(las=1, cex.lab=1.4, cex.axis=1.4, lwd=2)
```


ANOVA â€“ Analysis of Variances
--------------------------------------------------------------------------------
* Testing of complex hypothesis as a whole, e.g.:
    * more than two samples (multiple test problem),
    * several multiple factors (multiway ANOVA)
    * elimination of covariates (ANCOVA)
    * fixed and/or random effects
    (variance decomposition methods, mixed effects models)
* Different application scenarios:
    * explorative use: Which influence factors are important?
    * descriptive use: Fitting of models for process description and
    forecasting.
    * significance tests.
* ANOVA methods are (in most cases) based on linear models.



A practical example
--------------------------------

![](img/ansaetze.jpg)


### Scientific question

Find a suitable medium for growth experiments with green algae:

* Cheap, easy to handle
* Suitable for students courses and classroom experiments

### Idea


* Use a commercial fertilizer with the main nutrients N and P
* Mineral water with trace elements
* Does non-sparkling mineral water contain enough $\mathrm{HCO_3^-}$?
* Test how to improve ($\mathrm{CO_2}$) availability for photosynthesis

Application
--------------------------------------------------------------------------------

### 7 Different treatments

* Fertilizer solution in closed bottles 
* Fertilizer solution in open bottles ($\mathrm{CO_2}$ from air)
* Fertilizer + Sugar (organic C source)
* Fertilizer + additional $\mathrm{HCO_3^-}$ (add $\mathrm{CaCO_3}$ to sparkling mineral water)
* A standard algae growth medium ("Basal medium") for comparison
* Deionized ("destilled") water and tap water for comparison

Experimental design
--------------------------------------------------------------------------------

<div align="center">
<img src="img/ruettler.jpg" height=600>
</div>

<div style="padding-left: 10ex;">
* each treatment with 3 replicates
* randomized experiment on a shaker
* 16:8 light:dark-cycle
* Measurement directly in the bottles using a self-made [turbidity meter](https://tpetzoldt.github.io/growthlab/doc/versuchsaufbau.html)
</div>

Results
--------------------------------------------------------------------------------

<div class="vbox"></div>
<div class="hbox">
![](img/ansaetze2.jpg)
Fertilizer -- Open Bottle -- F. + Sugar -- F. + CaCO3 -- Basal medium -- A. dest -- Tap water
</div>

The data set
--------------------------------

```{r, echo=FALSE}
dat <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)

xdat <- 
  dat %>% 
  pivot_wider(id_cols = treat, names_from=rep, values_from=growth, names_prefix="replicate ")
```


```{r}
xdat %>% 
  kable('html', caption="Data set: Growth from day 2 to day 6 (in relative units)") %>% 
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

* NA means "not available", i.e. a missing value
* The crosstable structure is compact and nice for a slide, but not suitable for
data analysis
* therefore, we use the long table format instead


Data in long format
--------------------------------------------------------------------------------

<div class='left' style='float:left;width:48%'>

<p style="padding-bottom: 30ex">&nbsp;</p>

## Advantages
* looks "stupid" but is better for data analysis
* dependend **growth** and explanation variable **treat** clearly visible
* easily extensible to $>1$ explanation variable
</div>

<div class='right' style='float:left;width:48%'>

```{r}
dat %>% 
  kable('html', caption="Data set: Growth from day 2 to day 6 (in relative units)") %>% 
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

</div>

The data in R
--------------------------------------------------------------------------------

```{r, echo=TRUE}
dat <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)
```

... can be read from a **csv**-file or entered directly in the code.

Visualization
--------------------------------------------------------------------------------

```{r echo=TRUE}
boxplot(growth ~ treat, data=dat)
abline(h=0, lty="dashed", col="grey")
```

But as we have only 2-3 replicates per box, it is better to plot the all values
separately using `stripchart`:

```{r}
stripchart(growth ~ treat, data=dat, vertical=TRUE)
```


Statistical approach and the Bonferroni law
--------------------------------------------------------------------------------

### Questions

* Are the treatments different?
* Which medium is the best?
* Is the best medium significantly better than the others?

### Hypotheses

* $H_0$ growth is the same in all treatments
* $H_A$ differences between media

### Why can't we apply just several t-tests?

* If we have 7 treatments and want to test all against each other, we would need $7 \cdot (7 - 1) / 2 = 21$&nbsp; tests.
* If we set $\alpha = 0.05$ we will get 5% false positives, i.e. one of 20 tests 
is on average false positive
* This means that we do N tests, we may increase the overall $\alpha$ error in the worst case to a value of $N\alpha$.
* This is called **alpha-error-inflation** or the **Bonferroni** law:

\[
\alpha_{total} \le \sum_{i=1}^{N} \alpha_i = N \cdot \alpha
\]


* If we ignore the Bonferroni law, we end in **statistical fishing** i.e. we
get spurious results just by chance.

### Solutions

* One approach can be to down-correct the alpha errors so that $\alpha_{total} = 0.05$
* The preferred approach is to use a method that does all tests simultanaeously: the ANOVA.

ANOVA: Analysis of variances
--------------------------------------------------------------------------------

### Basic Idea

* split the total variance into effect(s) and errors:

\[
s_y^2 = s^2_\mathrm{effect} + s^2_{\varepsilon}
\]

* The most surprising is, that we use variances to compare mean values. The reason 
for this is, that differences of means contribute to the total variance of the
whole sample. Sometimes, the variance components are also called **variance within** ($s^2_\varepsilon$) and variance **between** samples.
* The way how to separate variances is a linear model.

<p style="padding-bottom: 5ex">&nbsp;</p>

### Example

We have two brands of Clementines from a shop "E", that we encode as "EB" and "EP".
We want to know whether the premium brand ("P") and the basic brand ("B") have
a different weight.

Instead of a t-test we encode "EB" with 1 and "EP" with 2.  

```{r, echo=TRUE}
clem_edeka <- data.frame(
  brand = c("EP", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", 
            "EB", "EB", "EB", "EP", "EP", "EP", "EP", "EP", "EP", "EP", "EB", "EP"),
  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, 
             81, 96, 82, 98, 80, 107, 88)
)

clem_edeka$code <- as.numeric(factor(clem_edeka$brand))

plot(weight ~ code, data=clem_edeka, axe=FALSE)
m <- lm(weight ~ code, data=clem_edeka)
axis(1, at=c(1,2), labels=c("EB", "EP")); axis(2); box()
abline(m, col="blue")
```

### Total variance

```{r, echo=TRUE}
(var_tot <- var(clem_edeka$weight))
```

### Residual variance (alias "within variance")

```{r, echo=TRUE}
(var_res <- var(residuals(m)))
```

### Between variance or explained variance

```{r, echo=TRUE}
1 - var_res / var_tot
```


**Exercise:**

* Perform a t-Test for the two Clementine brands
* Compare the p-value of the t-test with the p-value of an ANOVA


ANOVA in R
--------------------------------------------------------------------------------

Back to the algae growth data. Let's call the linear model `m`:

```{r echo=TRUE}
m <- lm(growth ~ treat, data=dat)
```

We can then print the coefficients of the linear model with `summary(m)`, but 
the more common way is to use the `anova`function

```{r echo=TRUE}
anova(m)
```

The ANOVA table shows the F-tests testing for significance of all factors. In the table above, 
we have only one single factor.

We see that the treatment had a significant effect.


Posthoc tests
--------------------------------------------------------------------------------

The test above showed only, that the **factor** "treatment" had a significant effect, but we don't know which **levels** of the factor are different. Here we apply a so-called posthoc test.

Different posthoc tests exist, here we use the **Tukey HSD test** that is the most common.

The `TukeyHSD` function has a numerical and a graphical output.

### Tukey HSD test

```{r, echo=TRUE}
tk <- TukeyHSD(aov(m))
tk
```

### Graphical output

```{r, echo=TRUE}
par(las = 1)             # las = 1 make y annotation horizontal
par(mar = c(4, 10, 3, 1)) # more space at the left for axis annotation
plot(tk)
```



ANOVA assumptions and diagnostics
--------------------------------------------------------------------------------

The assumptions of the ANOVA are the same as for the linear model. In short:

1. Independence of errors
2. Variance homogeneity
3. Approximate normality of errors

Again, graphical methods are preferred. The easiest is `plot(m)`.

```{r echo=TRUE}
plot(m, which=1)
```


```{r echo=TRUE}
plot(m, which=2)
```

It is also possible to test variance homogeneity. Instead of an F-test that can only
compare two variances, we need a test that can compare more than two, for example the
Fligner-Killeen-test:

```{r, echo=TRUE}
fligner.test(growth ~ treat, data=dat)
```

One-way ANOVA with heterogeneous variances
--------------------------------------------------------------------------------

If variances are not equal we can use an extension of the Welch test for $\ge 2$ samples, in R called `oneway.test` instead of the one-way ANOVA :

```{r, echo=TRUE}
oneway.test(growth ~ treat, data=dat)
```


Two-way ANOVA
--------------------------------------------------------------------------------

```{r}
hams <- data.frame(No=1:12,
                   growth=c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   diet= rep(c("A", "B", "C"), each=2),
                   coat= rep(c("light", "dark"), each=6)
                   )
```


* Example from a statistics text book, Crawley (2002)
* Effects of diet and coat color on growth of Hamsters  in Gramm per time (constructed data set)

<div style="align: center">
<img src="img/hams-crosstable.jpg" alt="Hamster growth" style="width:30%">
</div>

* Factorial experiment (**with replicates**)
* Each factor combination (cell) contains more than one observation.

Without replication: only one experiment per factor combination. This is possible,
but does not allow to identify interaction effects.

Tidy data
--------------------------------------------------------------------------------

```{r, echo=TRUE}
hams <- data.frame(No = 1:12,
                   growth = c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   diet = rep(c("A", "B", "C"), each=2),
                   coat = rep(c("light", "dark"), each=6)
                   )
```

```{r}
hams %>% 
  kable('html', caption="Data set: Growth of hamsters (in gramm)") %>% 
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

Visualization and ANOVA
--------------------------------------------------------------------------------
```{r}
par(mfrow=c(1, 2))
boxplot(growth ~ diet, data = hams, col="wheat")
boxplot(growth ~ coat, data=hams, col="wheat")
```

### ANOVA

```{r, echo=TRUE}
m <- lm(growth~coat*diet, data=hams)
anova(m)
```

### Interaction plot

```{r, echo=TRUE}
with(hams, interaction.plot(diet, coat, growth, col=c("brown", "orange"), lty=1, lwd=2))
```

Diagnostics
--------------------------------------------------------------------------------

### Assumptions

1. independence of measurements (within samples)
2. Variance homogeneity of residuals
3. Normal distribution of residuals

Note: test of assumptions only possible after fitting the model.

â‡’ Fit the ANOVA model first, then check if it was correct!

### Diagnostic tools

* Box plot
* Plot of residuals vs. mean values
* Q-Q-plot of residuals
* Fligner-Killeen test (alternative: some people recommend the Levene-Test)

```{r, echo=TRUE}
par(mfrow=c(1, 2))
par(cex=1.2, las=1)
qqnorm(residuals(m))
qqline(residuals(m))

plot(residuals(m)~fitted(m))
abline(h=0)
```  

```{r, echo=TRUE}  
fligner.test(growth ~ interaction(coat, diet), data=hams)
```

Sequential Holm-Bonferroni method
--------------------------------------------------------------------------------

* Also called Holm procedure [@Holm1979]
* Easy to use
* Can be applied to any multiple test problem
* Less conservative that ordinary Bonferroni correction, but ...
* ... still a very conservative approach
* see also [Wikipedia](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method)

### Algorithm

1. Select smallest $p$ out of all $n$ $p$-values
2. If $p \cdot n < \alpha$ $\Rightarrow$ significant, else <bf>STOP</bf>
3. Set $n âˆ’ 1 \rightarrow n$, remove smallest $p$ from the list and go to step 1.


### Example

Growth rate per day ($d^{-1}$) of blue-green algae cultures (*Pseudanabaena*) after adding
toxic peptides from another blue-green algae (*Microcystis*).

The original hypothesis was that Microcystin LR (MCYST) or a derivative of it 
(Substance A) inhibits growth.

```{r}
mcyst <-  data.frame(treat = factor(c(rep("Control", 5),
                                       rep("MCYST", 5),
                                       rep("Subst A", 5)),
                                levels=c("Control", "MCYST", "Subst A")),
                      mu   = c(0.086, 0.101, 0.086, 0.086, 0.099,
                               0.092, 0.088, 0.093, 0.088, 0.086,
                               0.095, 0.102, 0.106, 0.106, 0.106)
                     )
```

### Approach 1: one-way ANOVA

```{r}
par(mar=c(4, 8, 2, 1), las=1)
m <- lm(mu ~ treat, data=mcyst)
anova(m)
plot(TukeyHSD(aov(m)))
```

### Approach 2: multiple t-Tests with sequential Bonferroni correction

We separate the data set in single subsets:

```{r}
Control <- mcyst$mu[mcyst$treat == "Control"]
MCYST   <- mcyst$mu[mcyst$treat == "MCYST"]
SubstA  <- mcyst$mu[mcyst$treat == "Subst A"]
```

and perform 3 t-Tests:

```{r}
p1 <- t.test(Control, MCYST)$p.value
p2 <- t.test(Control, SubstA)$p.value
p3 <- t.test(MCYST, SubstA)$p.value
```

The following shows the raw p-values without correction:

```{r}
c(p1, p2, p3)
```

and with Holm correction:

```{r}
p.adjust(c(p1, p2, p3))
```
### Conclusions I

#### Statistical methods

We see that only the last p-value (MCYST vs. Subst A) remains significant. 
This indicates that Holm corrected t-tests are more conservative than TukeyHSD 
(only one compared to two significant) effects.

A ANOVA with posthoc test is in general preferred but the sequential Bonferroni
can be helpful in special cases. Moreover, it demonstrates clearly that massive
multiple testing needs to be avoided.

#### Interpretation

Regarding our original hypothesis, we can see that MCYST and Subst. A did not
inhibit growth of *Pseudanabaena*. in fact Subst. A seemed to stimulate growth.

This was contrary to our expectations -- the biological reason was then found 10 years later.

More about this can be found in @Jahnichen2001, @Jahnichen2007, @Jahnichen2011 
and @Zilliges2011


Outlook
--------------------------------------------------------------------------------

### ... will follow next


* ANCOVA
* Type II and III ANOVA
* Model Selection
* AIC, BIC
* step
* Summary
* Avoid p-value hacking!


Bibliography
--------------------------------------------------------------------------------
